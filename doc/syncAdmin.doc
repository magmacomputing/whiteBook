The whole point of checking Snap#0 is to compare Firestore local-cache with IDB local-store
Snap #0 is always a full-set.
If we can reconcile Snap#0, then we don't need to slow down the User with un-necessary idb.upgrade

~~~
(IdbService instantiated, which creates a basic admin_ dbase with three stores)
listener on admin_   forced to happen first
select all from this.idb.getIndex(_schema_.byDBase, 'admin')
so, I know I need to listen to '_schema_' and '_config_'  ('_local_' is expired, so ignored)
2x listeners are created, with a auto-off of 2 seconds.
1 for syncAdmin, 1 for syncStore

we now receive 2x Snap 0's.
1) all snaps for non-_schema_ -> syncStore callback

2) snap 0 for _schema_ -> syncAdmin callback
if snap.cnt === idbCount(_schema_), exclude _expire
	unblock
	return;					// nothing to do

~~~
If snap 1 adds a new Store to _schema_, idb.upgrade(),
		then (if dbase on and store !_expire) start another listener
If snap 1 removes a Store, then stop listener, update _schema_ with _expire:getStamp()
If snap 1 modifies a Store to expire, then stop listener, update _schema_ with _expire:getStamp()
If snap 1 modifies a Store un expire, then start another listener, update _schema_ with _expire:0
If snap 1 modifies a Store but does not touch expire, idb.upgrade()   to figure out what to do.

~~~
every time a listener is established, check _config_ for auto-off.

If snap 1 changes _config_ to wait, then adjust associated listener with a time-out
If snap 1 changes _config_ un wait, then adjust associated listener (if any) to remove time-out (??)

~~
# snap 0
Fire has 3+ and 1-
Idb has 0 and 0

idb.upgrade(fire)
Idb has 3+ and 1-
~~~
snap 1
Fire has 1+

idb.upgrade(fire 1+)
idb has 4+ and 1-

~~~~~~~~~~~~~~~~~~~~~~~
# next day
# snap 0
Fire has 4+ and 1-
Idb has 4+ and 1-
ignore
~~~
snap 1
Fire has 1-

idb.upgrade(fire 1-)
idb has 3+ and 2-